{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "\n",
    "from imitation.algorithms import bc\n",
    "from imitation.data import rollout\n",
    "from imitation.data.wrappers import RolloutInfoWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractPOVAndTranspose(gym.ObservationWrapper):\n",
    "    \"\"\"\n",
    "    Basically what it says on the tin. Extracts only the POV observation out of the `obs` dict,\n",
    "    and transposes those observations to be in the (C, H, W) format used by stable_baselines and imitation\n",
    "    \"\"\"\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        non_transposed_shape = self.env.observation_space['pov'].shape\n",
    "        self.high = np.max(self.env.observation_space['pov'].high)\n",
    "        transposed_shape = (non_transposed_shape[2],\n",
    "                            non_transposed_shape[0],\n",
    "                            non_transposed_shape[1])\n",
    "        # Note: this assumes the Box is of the form where low/high values are vector but need to be scalar\n",
    "        transposed_obs_space = gym.spaces.Box(low=np.min(self.env.observation_space['pov'].low),\n",
    "                                              high=np.max(self.env.observation_space['pov'].high),\n",
    "                                              shape=transposed_shape,\n",
    "                                              dtype=np.uint8)\n",
    "        self.observation_space = transposed_obs_space\n",
    "\n",
    "    def observation(self, observation):\n",
    "        # Minecraft returns shapes in NHWC by default\n",
    "        return np.swapaxes(observation['pov'], -1, -3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'minerl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 45\u001b[0m\n\u001b[1;32m     40\u001b[0m             out[k] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqueeze(v)\n\u001b[1;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_data_iterator\u001b[39m(\n\u001b[1;32m     44\u001b[0m         wrapped_dummy_env: gym\u001b[39m.\u001b[39mEnv,\n\u001b[0;32m---> 45\u001b[0m         data_pipeline: minerl\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataPipeline,\n\u001b[1;32m     46\u001b[0m         batch_size: \u001b[39mint\u001b[39m,\n\u001b[1;32m     47\u001b[0m         buffer_size: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m15000\u001b[39m,\n\u001b[1;32m     48\u001b[0m         num_epochs: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     49\u001b[0m         num_batches: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     50\u001b[0m         remove_no_ops: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     51\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[1;32m     52\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[39m    Construct a data iterator that (1) loads data from disk, and (2) wraps it in the set of\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39m    wrappers that have been applied to `wrapped_dummy_env`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39m         \"next_obs\", \"dones\".\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     buffered_iterator \u001b[39m=\u001b[39m BufferedBatchIter(data_pipeline, buffer_target_size\u001b[39m=\u001b[39mbuffer_size)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'minerl' is not defined"
     ]
    }
   ],
   "source": [
    "## These functions are available in the `basalt_utils` package \n",
    "## provided in the basalt template repo \n",
    "\n",
    "\n",
    "def optional_observation_map(env, inner_obs):\n",
    "    \"\"\"\n",
    "    If the env implements the `observation` function (i.e. if one of the\n",
    "    wrappers is an ObservationWrapper), call that `observation` transformation\n",
    "    on the observation produced by the inner environment\n",
    "    \"\"\"\n",
    "    if hasattr(env, 'observation'):\n",
    "        return env.observation(inner_obs)\n",
    "    else:\n",
    "        return inner_obs\n",
    "\n",
    "\n",
    "def optional_action_map(env, inner_action):\n",
    "    \"\"\"\n",
    "    This is doing something slightly tricky that is explained in the documentation for\n",
    "    RecursiveActionWrapper (which TODO should eventually be in MineRL)\n",
    "    Basically, it needs to apply `reverse_action` transformations from the inside out\n",
    "    when converting the actions stored and used in a dataset\n",
    "\n",
    "    \"\"\"\n",
    "    if hasattr(env, 'wrap_action'):\n",
    "        return env.wrap_action(inner_action)\n",
    "    else:\n",
    "        return inner_action\n",
    "\n",
    "\n",
    "def recursive_squeeze(dictlike):\n",
    "    \"\"\"\n",
    "    Take a possibly-nested dictionary-like object of which all leaf elements are numpy ar\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    for k, v in dictlike.items():\n",
    "        if isinstance(v, dict):\n",
    "            out[k] = recursive_squeeze(v)\n",
    "        else:\n",
    "            out[k] = np.squeeze(v)\n",
    "    return out\n",
    "    \n",
    "def create_data_iterator(\n",
    "        wrapped_dummy_env: gym.Env,\n",
    "        data_pipeline: minerl.data.DataPipeline,\n",
    "        batch_size: int,\n",
    "        buffer_size: int = 15000,\n",
    "        num_epochs: int = None,\n",
    "        num_batches: int = None,\n",
    "        remove_no_ops: bool = False,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Construct a data iterator that (1) loads data from disk, and (2) wraps it in the set of\n",
    "    wrappers that have been applied to `wrapped_dummy_env`.\n",
    "\n",
    "    :param wrapped_dummy_env: An environment that mimics the base environment and wrappers we'll be using for training,\n",
    "    but doesn't actually call Minecraft\n",
    "    :param data_pipeline: A MineRL DataPipeline object that can handle loading data from disk\n",
    "    :param batch_size: The batch size we want the iterator to produce\n",
    "    :param num_epochs: The number of epochs we want the underlying iterator to run for\n",
    "    :param num_batches: The number of batches we want the underlying iterator to run for\n",
    "    :param remove_no_ops: Whether to remove transitions with no-op demonstrator actions from batches\n",
    "    as they are generated. For now, this corresponds to all-zeros.\n",
    "\n",
    "    :yield: Wrapped observations and actions in a dict with the keys \"obs\", \"acts\", \"rews\",\n",
    "         \"next_obs\", \"dones\".\n",
    "    \"\"\"\n",
    "    buffered_iterator = BufferedBatchIter(data_pipeline, buffer_target_size=buffer_size)\n",
    "    for current_obs, action, reward, next_obs, done in buffered_iterator.buffered_batch_iter(batch_size=batch_size,\n",
    "                                                                                             num_epochs=num_epochs,\n",
    "                                                                                             num_batches=num_batches):\n",
    "        wrapped_obs = optional_observation_map(wrapped_dummy_env,\n",
    "                                               recursive_squeeze(current_obs))\n",
    "        wrapped_next_obs = optional_observation_map(wrapped_dummy_env,\n",
    "                                                    recursive_squeeze(next_obs))\n",
    "        wrapped_action = optional_action_map(wrapped_dummy_env,\n",
    "                                             recursive_squeeze(action))\n",
    "\n",
    "        if remove_no_ops:\n",
    "            # This definitely makes assumptions about the action space, namely that all-zeros corresponds to a no-op\n",
    "            not_no_op_indices = wrapped_action.sum(axis=1) != 0\n",
    "            wrapped_obs = wrapped_obs[not_no_op_indices]\n",
    "            wrapped_next_obs = wrapped_next_obs[not_no_op_indices]\n",
    "            wrapped_action = wrapped_action[not_no_op_indices]\n",
    "\n",
    "        return_dict = dict(obs=wrapped_obs,\n",
    "                           acts=wrapped_action,\n",
    "                           rews=reward,\n",
    "                           next_obs=wrapped_next_obs,\n",
    "                           dones=done)\n",
    "\n",
    "        yield return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bc-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
