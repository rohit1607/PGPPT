# NEED TO UPDATE AS PER DOLS - SHUBHAM
program: train.py
method: grid
name: my_tt_sweep
project: my_translation_transformer
metric: 
  name: ETA
  goal: minimize

parameters:
  env_name:
    value: "gym_examples/contGrid-v5_1"
  state_dim:
    value: 3
  action_dim:
    value: 1
  action_range:
    value: [0, 6.28318]
  F:
    value: 1
  vel_field:
    value: "/home/rohit/Documents/Research/Planning_with_transformers/Translation_transformer/my-translat-transformer/data/DG3/raw_data/nT_120"
  del_t:
    value: 1.
  scale_velocity:
    value: False
  vmax_by_F:
    value: 1
  space_scale:
    value: 1
  target_radius:
    value: 2

  add_transition_noise_during_inf:
    value: False
  noise_var:
    value: [0.1,0]

  dataset_name:
    value: "GPTdset_DG3"
  dataset_path:
    value: "data/GPT_dset_DG3/static_obs/GPTdset_DG3_g100x100x120_r5k_Obsv1_w5_1dataset_v1.pkl"
  log_dir:
    value: "log"
  params2_name:
    value: "data/GPT_dset_DG3/static_obs/GPTdset_DG3_g100x100x120_r5k_Obsv1_w5_1/params.yml"

  random_split:
    value: True
  split_tr_tst_val:
    value: [0.8, 0.05, 0.15]
  split_ran_seed:
    value: 42
  comp_val_loss:
    value: False
  translate_earlybreaks: 
    value: [100, 100, 250]


  max_eval_ep_len:
    value: 120
  num_eval_ep:
    value: 200
  eval_inerval:
    value: 1
  batch_size:
    value: 32

  lr:
    values: [0.00001, 0.000001]
  use_scheduler:
    value: True
  wt_decay:
    value: 0.0001
  warmup_steps:
    value: 500
  num_epochs:
    value: 30
  num_updates_per_iter:
    value: 500
  add_target_loss:
    value: False
  a_tl:
    value: 1000

  target_conditioning:
    value: False 
  num_encoder_layers:
    value: 2
  num_decoder_layers:
    value: 2
  context_len:
    value: 120
  embed_dim:
    values: [50,150]
  n_heads:
    value: 10
  dropout_p:
    value: 0.1

  device:
    value: 'cuda'


  
  
 
